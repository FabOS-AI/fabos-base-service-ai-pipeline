(window.webpackJsonp=window.webpackJsonp||[]).push([[11],{293:function(e,t,a){"use strict";a.r(t);var n=a(15),o=Object(n.a)({},(function(){var e=this,t=e._self._c;return t("ContentSlotsDistributor",{attrs:{"slot-key":e.$parent.slotKey}},[t("h1",{attrs:{id:"ai-toolbox"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#ai-toolbox"}},[e._v("#")]),e._v(" AI ToolBox")]),e._v(" "),t("p",[e._v("This module has an api for creating and training AI models for a given dataset.\nIt makes use of AutoML to make models without needing the user to configure model parameters, but the user still needs to provide some hyperparameters.\nThis is hosted on the port '5001'.")]),e._v(" "),t("h2",{attrs:{id:"apis"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#apis"}},[e._v("#")]),e._v(" APIs")]),e._v(" "),t("details",{staticClass:"custom-block details"},[t("summary",[e._v("AutoML")]),e._v(" "),t("p",[e._v("This API calls the AI-toolbox backend to create and train AI models.\nIt reads all the hyperparameters required for model training from http request along with the training data.\nTo call this API the request can be send to AI-toolbox port + '/automl'.")]),e._v(" "),t("p",[e._v("function:")]),e._v(" "),t("div",{staticClass:"language- extra-class"},[t("pre",[t("code",[e._v("automl()\n\nThis function extracts all the parameters from the http request to train the model along with the training data.\nThe training dataset if available as separate feature and target, i.e., X and y then it calls \n:ref:`tb.automl_tts(X_train, y_train, model_param, model_epoch, model_max_trials, model_loss, model_metric) <aibackend>`\nand if that is not available but just the data and target parameter then it calls\n:ref:`tb.automl_df(df_data, target_param, model_param, model_epoch, model_max_trials, model_loss, model_metric, test_size) <aibackend>`\nto create and train the AI model.\n\nAfter the model is trained it saves the model as zip file at the path provided and returns the model and path as a dictionary in json::\n\n    # Model folder\n    model_path_temp = os.path.join(os.getcwd(), 'Models')\n\n    # Path to the model folder\n    model_name_path = os.path.join(model_path_temp, model_name)\n    model.save(model_name_path, save_format='tf')\n\n    # Generate .zip file\n    model_zip_temp = os.path.join(os.getcwd(), 'zipped_model')\n    model_name_zip = os.path.join(model_zip_temp, model_name)\n    filename = shutil.make_archive(model_name_zip, 'zip', model_name_path)\n\n:return: Returns the onnx model and and path as dictionary in json\n:rtype: JSON\n")])])])]),e._v(" "),t("details",{staticClass:"custom-block details"},[t("summary",[e._v("Transfer Learning")]),e._v(" "),t("p",[e._v("This API calls the AI-toolbox backend to change the layers of a pre-existing model and re-train it for a similar problem.\nIt reads all the necessary hyper-parameters along with the model and the number of layers that needs to be changed.\nTo call this API the request can be send to AI-toolbox port + '/transfer-learning'")]),e._v(" "),t("p",[e._v("function:")]),e._v(" "),t("div",{staticClass:"language- extra-class"},[t("pre",[t("code",[e._v("tf()\n\nThis extracts all the parameters from the http request to train the model along with the training data and the number of layers to be replaced.\nIt calls the function tb.tf(filename, df_data, test_size, target_param, loss, metric, epochs, n) to\nre-train the models by replacing 'n' layers from the origninal model.\n\n:return: Returns the model and a path as dictionary in json\n:rtype: JSON\n")])])])])])}),[],!1,null,null,null);t.default=o.exports}}]);